import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, TypedDict

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from titanicprediction.core.services import ServiceFactory, TrainingConfig
from titanicprediction.data.analysis import EDAVisualizer
from titanicprediction.data.preprocessing import PreprocessorFactory
from titanicprediction.data.repositories import CSVDataRepository
from titanicprediction.entities.core import Dataset, Passenger, TrainedModel

sys.path.append(os.path.dirname(os.path.abspath(__file__)))


class AppState(TypedDict):
    current_page: str
    dataset: Optional[Dataset]
    trained_model: Optional[TrainedModel]
    preprocessing_pipeline: Optional[Any]
    current_predictions: List[Any]
    training_history: List[float]
    training_result: Optional[Any]


class DataTableComponent:
    def render(
        self, data: pd.DataFrame, title: str = "Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…", page_size: int = 10
    ) -> None:
        st.subheader(title)

        col1, col2 = st.columns([2, 1])

        with col1:
            search_term = st.text_input("ĞŸĞ¾Ğ¸ÑĞº...", key=f"search_{title}")

        with col2:
            sort_column = st.selectbox("Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°", data.columns, key=f"sort_{title}")

        if search_term:
            filtered_data = data[
                data.astype(str).apply(
                    lambda x: x.str.contains(search_term, case=False).any(), axis=1
                )
            ]
        else:
            filtered_data = data

        if sort_column in filtered_data.columns:
            filtered_data = filtered_data.sort_values(by=sort_column)

        st.dataframe(filtered_data, width="stretch")

        total_pages = max(1, len(filtered_data) // page_size)
        current_page = st.number_input(
            "Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°", min_value=1, max_value=total_pages, value=1, key=f"page_{title}"
        )

        start_idx = (current_page - 1) * page_size
        end_idx = start_idx + page_size

        st.write(
            f"ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ğ½Ñ‹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ {start_idx + 1} Ğ´Ğ¾ {min(end_idx, len(filtered_data))} Ğ¸Ğ· {len(filtered_data)}"
        )

        if st.button("Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² CSV", key=f"export_{title}"):
            csv = filtered_data.to_csv(index=False)
            st.download_button(
                label="Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV",
                data=csv,
                file_name="titanic_data.csv",
                mime="text/csv",
            )


class PlotComponent:
    def render(self, plot_path: Path, title: str = "Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº") -> None:
        st.subheader(title)

        try:
            st.image(str(plot_path), width="stretch")
        except Exception as e:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°: {e}")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ", key=f"refresh_{title}"):
                st.rerun()

        with col2:
            if st.button("Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ", key=f"download_{title}"):
                with open(plot_path, "rb") as file:
                    st.download_button(
                        label="Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ",
                        data=file,
                        file_name=plot_path.name,
                        mime="image/png",
                    )


class ModelMetricsComponent:
    def render(self, metrics: Dict[str, float], confusion_matrix: np.ndarray) -> None:
        st.subheader("ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Accuracy / Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ", f"{metrics.get('accuracy', 0):.3f}")

        with col2:
            st.metric(
                "Precision / Ğ¢Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²ĞµÑ€Ğ½Ğ¾ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ…",
                f"{metrics.get('precision', 0):.3f}",
            )

        with col3:
            st.metric("Recall / ĞŸĞ¾Ğ»Ğ½Ğ¾Ñ‚Ğ°", f"{metrics.get('recall', 0):.3f}")

        with col4:
            st.metric("F1-Score / F1-Ğ¼ĞµÑ€Ğ°", f"{metrics.get('f1_score', 0):.3f}")

        st.subheader("ĞœĞ°Ñ‚Ñ€Ğ¸Ñ†Ğ° Ğ½ĞµÑ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ĞµĞ¹")
        self._render_confusion_matrix(confusion_matrix)

        st.subheader("ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸")
        self._render_detailed_metrics(metrics)

    def _render_confusion_matrix(self, cm: np.ndarray) -> None:
        fig = px.imshow(
            cm,
            labels=dict(x="ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¾", y="ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾", color="Ğ§Ğ¸ÑĞ»Ğ¾"),
            x=["ĞĞµ Ğ²Ñ‹Ğ¶Ğ¸Ğ»Ğ¾", "Ğ’Ñ‹Ğ¶Ğ¸Ğ»Ğ¾"],
            y=["ĞĞµ Ğ²Ñ‹Ğ¶Ğ¸Ğ»Ğ¾", "Ğ’Ñ‹Ğ¶Ğ¸Ğ»Ğ¾"],
            color_continuous_scale="Blues",
            aspect="auto",
        )

        for i in range(len(cm)):
            for j in range(len(cm)):
                fig.add_annotation(
                    x=j,
                    y=i,
                    text=str(cm[i, j]),
                    showarrow=False,
                    font=dict(color="red" if cm[i, j] > cm.max() / 2 else "black"),
                )

        st.plotly_chart(fig, width="stretch")

    def _render_detailed_metrics(self, metrics: Dict[str, float]) -> None:
        detailed_metrics = {
            "ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸": ["Accuracy", "Precision", "Recall", "F1-Score", "Support"],
            "Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ": [
                metrics.get("accuracy", 0),
                metrics.get("precision", 0),
                metrics.get("recall", 0),
                metrics.get("f1_score", 0),
                metrics.get("support", 0),
            ],
        }

        st.dataframe(detailed_metrics, width="stretch")


class PredictionFormComponent:
    def render(self) -> Passenger:
        st.subheader("Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°Ñ…")

        with st.form("prediction_form"):
            col1, col2 = st.columns(2)

            with col1:
                pclass = st.selectbox("ĞšĞ»Ğ°ÑÑ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°", [1, 2, 3], index=0)
                sex = st.selectbox("ĞŸĞ¾Ğ»", ["male", "female"], index=0)
                age = st.slider("Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚", 0.0, 100.0, 30.0, 0.5)

            with col2:
                sibsp = st.number_input(
                    "Ğ‘Ñ€Ğ°Ñ‚ÑŒÑ Ğ¸ ÑĞµÑÑ‚Ñ€Ñ‹/Ğ¡ÑƒĞ¿Ñ€ÑƒĞ³Ğ¸", min_value=0, max_value=10, value=0
                )
                parch = st.number_input(
                    "Ğ Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸/Ğ”ĞµÑ‚Ğ¸", min_value=0, max_value=10, value=0
                )
                fare = st.number_input(
                    "ĞŸĞ»Ğ°Ñ‚Ğ°", min_value=0.0, max_value=600.0, value=50.0, step=1.0
                )

            embarked = st.selectbox("ĞŸĞ¾Ñ€Ñ‚ Ğ¿Ğ¾ÑĞ°Ğ´ĞºĞ¸", ["C", "Q", "S"], index=2)

            submitted = st.form_submit_button("ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑˆĞ°Ğ½Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ")

            if submitted:
                return Passenger(
                    passenger_id=0,
                    pclass=pclass,
                    name="ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ",
                    sex=sex,
                    age=age,
                    sibsp=sibsp,
                    parch=parch,
                    ticket="Ğ‘Ğ¸Ğ»ĞµÑ‚",
                    fare=fare,
                    cabin=None,
                    embarked=embarked,
                    survived=None,
                    title=None,
                )

        return None


class HomePage:
    def render(self, state) -> None:
        st.title("ğŸš¢ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ñ‚Ğ¸Ñ‚Ğ°Ğ½Ğ¸ĞºĞµ")
        st.markdown("---")

        st.header("ĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ¿Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ¼Ñƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown(
                """
### Ğ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ
Ğ’ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¼Ğ¸Ñ€Ğµ Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸ĞµĞ¼ AI-ÑÑ„ĞµÑ€Ñ‹ Ğ¼Ğ°Ğ»Ğ¾ Ğ»ÑĞ´ĞµĞ¹, Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼Ñ‹Ñ… Ñ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ±Ğ°Ğ·Ğ¾Ğ¹ Ğ¿Ğ¾ Ğ˜Ğ˜-Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°Ğ¼. Ğ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¾Ğ±Ñ‰ĞµÑÑ‚Ğ²Ğ¾ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ğ»Ğ¾ÑÑŒ Ğ½Ğ° Ğ´Ğ²Ğµ ĞºÑ€Ğ°Ğ¹Ğ½Ğ¾ÑÑ‚Ğ¸, Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ³Ğ»Ğ°ÑÑÑ‚ Ñ‡Ñ‚Ğ¾ Ğ˜Ğ˜ Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚ Ğ²ÑĞµÑ… Ğ½Ğ°Ñ, Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸ÑÑ‚Ñ‹ ÑƒĞ¹Ğ´ÑƒÑ‚ Ğ½Ğ° Ğ·Ğ°Ğ²Ğ¾Ğ´, Ğ° Ğ²Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ğ° Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ Ñ‡Ñ‚Ğ¾ Ğ˜Ğ˜ ÑÑ‚Ğ¾ Ğ²ÑĞµĞ¼Ğ¸Ñ€Ğ½Ñ‹Ğ¹ Ğ¿ÑƒĞ·Ñ‹Ñ€ÑŒ Ğ¸ Ğ±Ğ¸Ğ·Ğ½ĞµÑ. Ğ˜ Ñ‚Ğµ, Ğ¸ Ñ‚Ğµ Ğ¿Ñ€Ğ°Ğ²Ñ‹, Ğ¸ Ğ½Ğµ Ğ¿Ñ€Ğ°Ğ²Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾.
Ğ’ Ğ¸ÑĞºÑƒÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚Ğµ ĞµÑÑ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ². Ğ¡Ğ°Ğ¼Ğ°Ñ Ğ±Ğ°Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ â€” Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ (ÑĞ°Ğ¼Ğ°Ñ Ğ¿Ñ€Ğ¾ÑÑ‚ĞµĞ¹ÑˆĞ°Ñ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿ĞµÑ€ÑĞµĞ¿Ñ‚Ñ€Ğ¾Ğ½, Ğº Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñƒ), Ğ¾ Ñ‚Ğ¾Ğ¼ ĞºĞ°Ğº Ğ¸Ñ… ÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ ĞµÑÑ‚ÑŒ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸. ĞĞ¾ Ğ² ÑÑ„ĞµÑ€Ğµ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ² Ğ¼Ğ°Ğ»Ğ¾ ĞºÑ‚Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑŒ Ğ¾ Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ²Ğ°Ğ¶Ğ½ĞµĞ¹ÑˆĞµĞ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ â€” Machine Learning, Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸.
Ğ˜Ğ¼ĞµĞ½Ğ½Ğ¾ ÑÑ‚Ğ¾Ğ¹ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ğ¾ÑĞ²ÑÑ‰ĞµĞ½ Ğ¼Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚. Ğ¯ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒÑ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚ĞµĞ¹ÑˆÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ ÑĞ¼ĞµÑ€Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° Â«Ğ¢Ğ¸Ñ‚Ğ°Ğ½Ğ¸ĞºĞµÂ» Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑˆĞ°Ğ½Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ñ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¿Ğ¾ ĞºĞ»Ğ°ÑÑÑƒ Ğ±Ğ¸Ğ»ĞµÑ‚Ğ°, Ñ†ĞµĞ½Ñ‹ Ğ±Ğ¸Ğ»ĞµÑ‚Ğ°, Ğ¿Ğ¾Ğ»Ñƒ, Ğ¸ Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚Ñƒ. Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ñ‚Ñ€Ğ¾Ğ½ĞµÑ‚ ĞºĞ°Ğº Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ½Ğ°ÑƒĞºĞ¸ Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Data Science) Ñ‚Ğ°Ğº Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° (Ğ² Ğ²Ğ¸Ğ´Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¸ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚ÑĞºĞ¾Ğ³Ğ¾ ÑĞ¿ÑƒÑĞºĞ°).
ĞŸÑ€Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ñ Ğ±ÑƒĞ´Ñƒ ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼Ñƒ Ğ¿Ğ»Ğ°Ğ½Ñƒ:
1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….
2. ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ²ĞµĞ´Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ»Ñ Ğ½Ğ°Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ·Ğ°ĞºĞ¾Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹.
3. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… â€” Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ¾Ğ², ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹.
4. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ â€” Ñ‡ĞµÑ€ĞµĞ· Ğ»Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¼ ÑĞ¿ÑƒÑĞºĞ¾Ğ¼.
5. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
Ğ˜Ğ· ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°:
Ğ¦ĞµĞ»ÑŒ: Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ ML Ğ¸ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ.
ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: Ğ’ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¼Ğ¸Ñ€Ğµ Ñ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸ĞµĞ¼ AI-ÑÑ„ĞµÑ€Ñ‹ Ğ¼Ğ°Ğ»Ğ¾ Ğ»ÑĞ´ĞµĞ¹, Ğ·Ğ½Ğ°ĞºĞ¾Ğ¼Ñ‹Ñ… Ñ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ±Ğ°Ğ·Ğ¾Ğ¹ Ğ¿Ğ¾ Ğ˜Ğ˜-Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°Ğ¼.
ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: ĞĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¸ÑĞºÑƒÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ñ ML-Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ° â€” Ğ¾Ğ´Ğ½Ğ° Ğ¸Ğ· ÑĞ°Ğ¼Ñ‹Ñ… Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑÑ€ĞµĞ´Ğ¸ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….
Ğ¡Ñ„Ğ¾Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸:
1. Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ;
2. Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ Data Science Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸;
3. Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ½ÑƒÑ, Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚ÑĞºĞ¸Ğ¹ ÑĞ¿ÑƒÑĞº Ğ¸ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½ÑƒÑ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ;
4. Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸;
5. ĞŸÑ€Ğ¾Ğ²ĞµÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ğ²ĞµĞ´Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…;
6. ĞĞ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ ĞµĞµ;
7. Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ÑĞºĞ¸Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ.
            """
            )

        with col2:
            st.image(
                "https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/RMS_Titanic_3.jpg/800px-RMS_Titanic_3.jpg",
                caption="Ğ¢Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ğº",
                width="stretch",
            )

        st.markdown("---")

        st.header("Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚ĞµĞº")

        tech_cols = st.columns(4)

        with tech_cols[0]:
            st.subheader("ğŸ› ï¸ ĞœĞ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ")
            st.markdown(
                """
            - ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ
            - Ğ“Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ ÑĞ¿ÑƒÑĞº
            - NumPy/Pandas
            """
            )

        with tech_cols[1]:
            st.subheader("ğŸ“Š Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ")
            st.markdown(
                """
            - Matplotlib/Seaborn
            - Plotly
            - Streamlit
            """
            )

        with tech_cols[2]:
            st.subheader("ğŸ—ï¸ ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°")
            st.markdown(
                """
            - Ğ§Ğ¸ÑÑ‚Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°
            - SOLID
            - ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ĞĞĞŸ
            - ACID
            - DRY, KISS
            """
            )

        with tech_cols[3]:
            st.subheader("ğŸ“ˆ ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°")
            st.markdown(
                """
            - Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ EDA
            - ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            - Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
            - ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            """
            )

        st.markdown("---")

        st.header("ĞšĞ°Ğº Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ")

        steps = st.columns(3)

        with steps[0]:
            st.subheader("1. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
            st.markdown(
                "Ğ˜Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ¢Ğ¸Ñ‚Ğ°Ğ½Ğ¸ĞºĞ° Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°Ğ¼Ğ¸."
            )

        with steps[1]:
            st.subheader("2. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
            st.markdown(
                "Ğ¢Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ»Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸, Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸."
            )

        with steps[2]:
            st.subheader("3. ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ")
            st.markdown(
                "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ ÑˆĞ°Ğ½ÑĞ° Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°."
            )


class ModelExplanationPage:
    def render(self, state: AppState) -> None:
        st.title("ğŸ” ĞĞ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")

        if state.get("trained_model") is None:
            st.warning("ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿ĞµÑ€ĞµĞ´ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼.")
            return

        model = state["trained_model"]
        dataset = state["dataset"]

        tab1, tab2, tab3, tab4 = st.tabs(
            [
                "Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ„Ğ¸Ñ‡",
                "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ",
                "Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
                "ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°",
            ]
        )

        with tab1:
            self._render_feature_importance(state, model, dataset)

        with tab2:
            self._render_prediction_analysis(state)

        with tab3:
            self._render_model_insights(state, model, dataset)

        with tab4:
            self._render_advanced_analytics(state, model, dataset)

    def _render_feature_importance(
        self, state: AppState, model: TrainedModel, dataset: Dataset
    ):
        st.subheader("Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ„Ğ¸Ñ‡")

        importance_data = model.get_feature_importance()
        sorted_importance = dict(
            sorted(importance_data.items(), key=lambda x: x[1], reverse=True)
        )

        col1, col2 = st.columns([2, 1])

        with col1:
            fig = px.bar(
                x=list(sorted_importance.values())[:15],
                y=list(sorted_importance.keys())[:15],
                orientation="h",
                title="Ğ¢Ğ¾Ğ¿ 15 Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ñ… Ñ„Ğ¸Ñ‡",
                labels={"x": "Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ (%)", "y": "Ğ¤Ğ¸Ñ‡Ğ¸"},
            )
            fig.update_layout(showlegend=False, height=500)
            st.plotly_chart(fig, width="stretch")

        with col2:
            st.subheader("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ñ„Ğ¸Ñ‡")
            st.metric("Ğ’ÑĞµĞ³Ğ¾ Ñ„Ğ¸Ñ‡", len(sorted_importance))

            top_5_importance = sum(list(sorted_importance.values())[:5])
            st.metric("Ğ¢Ğ¾Ğ¿ 5 Ñ„Ğ¸Ñ‡ Ğ¿Ğ¾ Ğ²ĞºĞ»Ğ°Ğ´Ñƒ", f"{top_5_importance:.1f}%")

            st.write("**Ğ¢Ğ¾Ğ¿ 5 Ñ„Ğ¸Ñ‡:**")
            for i, (feature, importance) in enumerate(
                list(sorted_importance.items())[:5]
            ):
                st.write(f"{i + 1}. {feature}: {importance:.2f}%")

    def _render_prediction_analysis(self, state: AppState):
        st.subheader("Ğ˜Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ")

        if not state.get("current_predictions"):
            st.info("Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹Ñ‚Ğµ ĞºĞ°ĞºĞ¸Ğµ Ğ½Ğ¸Ğ±ÑƒĞ´ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ´ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾Ğ¼.")
            return

        latest_pred = state["current_predictions"][-1]
        model = state["trained_model"]
        preprocessor = state["preprocessing_pipeline"]

        prediction_service = ServiceFactory.create_prediction_service(
            model, preprocessor
        )
        explanation_service = ServiceFactory.create_explanation_service(
            prediction_service
        )

        explanation = explanation_service.explain_prediction(latest_pred.passenger)

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ")
            st.metric("Ğ¨Ğ°Ğ½Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ", f"{explanation.probability:.1%}")
            st.metric(
                "Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ",
                "Ğ’Ñ‹Ğ¶Ğ¸Ğ»" if explanation.prediction else "ĞĞµ Ğ²Ñ‹Ğ¶Ğ¸Ğ»",
            )
            st.metric("Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸", explanation.confidence_level)

            passenger = latest_pred.passenger
            st.write("**Ğ¤Ğ¸Ñ‡Ğ¸ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°:**")
            feature_data = {
                "ĞšĞ»Ğ°ÑÑ": passenger.pclass,
                "ĞŸĞ¾Ğ»": passenger.sex,
                "Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚": passenger.age,
                "Ğ‘Ñ€Ğ°Ñ‚ÑŒÑ Ğ¸ ÑĞµÑÑ‚Ñ€Ñ‹": passenger.sibsp,
                "Ğ Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸/Ğ´ĞµÑ‚Ğ¸": passenger.parch,
                "Ğ¡ÑƒĞ¼Ğ¼Ğ°": f"${passenger.fare:.2f}",
                "ĞŸĞ¾Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ñ‚": passenger.embarked,
            }

            for key, value in feature_data.items():
                st.write(f"- **{key}:** {value}")

        with col2:
            st.subheader("Ğ¤Ğ°ĞºÑ‚Ğ¾Ñ€Ñ‹, Ğ²Ğ»Ğ¸ÑÑÑ‰Ğ¸Ğµ Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ")
            for factor in explanation.decision_factors:
                st.write(f"â€¢ {factor}")

            st.subheader("Ğ¢Ğ¾Ğ¿ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ², Ğ²Ğ»Ğ¸ÑÑÑ‰Ğ¸Ñ… Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ")
            impact_df = pd.DataFrame(
                [
                    {
                        "feature": impact.feature_name,
                        "impact": impact.impact_score,
                        "contribution": f"{impact.contribution:.1%}",
                    }
                    for impact in explanation.feature_impacts[:10]
                ]
            )

            fig = px.bar(
                impact_df,
                x="impact",
                y="feature",
                orientation="h",
                title="Ğ¢Ğ¾Ğ¿ 10 Ñ„Ğ¸Ñ‡ Ğ²Ğ»Ğ¸ÑÑÑ‰Ğ¸Ğµ Ğ½Ğ° ÑÑ‚Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ",
                color=impact_df["impact"] > 0,
                color_discrete_map={True: "green", False: "red"},
            )
            fig.update_layout(showlegend=False)
            st.plotly_chart(fig, width="stretch")

    def _render_model_insights(
        self, state: AppState, model: TrainedModel, dataset: Dataset
    ):
        st.subheader("Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

        if state.get("training_result"):
            training_result = state["training_result"]

            col1, col2 = st.columns(2)

            with col1:
                st.write("**Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:**")
                st.write(f"- Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸: {training_result.final_loss:.6f}")
                st.write(f"- Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: {training_result.training_time:.2f}s")
                st.write(f"- ĞÑ†ĞµĞ½ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: {training_result.config.learning_rate}")
                st.write(f"- Ğ­Ğ¿Ğ¾Ñ…Ğ¸: {training_result.config.epochs}")

            with col2:
                st.write("**ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:**")
                st.write(f"- Ğ ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: {training_result.config.lambda_reg}")
                st.write(f"- Convergence Tol: {training_result.config.convergence_tol}")
                st.write("- ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€: Adam")

        st.subheader("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ† Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹")

        feature1 = st.selectbox(
            "ĞŸĞµÑ€Ğ²Ğ°Ñ Ñ„Ğ¸Ñ‡Ğ°", options=dataset.feature_names[:10], index=0, key="feature1"
        )
        feature2 = st.selectbox(
            "Ğ’Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ„Ğ¸Ñ‡Ğ°",
            options=dataset.feature_names[:10],
            index=1,
            key="feature2",
        )

        if st.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ 2D Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº"):
            self._generate_2d_analysis(feature1, feature2, model, dataset)

    def _generate_2d_analysis(
        self, feature1: str, feature2: str, model: TrainedModel, dataset: Dataset
    ):
        try:
            fig = px.scatter(
                dataset.features.assign(Survived=dataset.target),
                x=feature1,
                y=feature2,
                color="Survived",
                title=f"Decision Pattern: {feature1} vs {feature2}",
                color_discrete_map={0: "red", 1: "green"},
            )
            st.plotly_chart(fig, width="stretch")
        except Exception as e:
            st.error(f"Could not generate 2D analysis: {e}")

    def _render_advanced_analytics(
        self, state: AppState, model: TrainedModel, dataset: Dataset
    ):
        st.subheader("ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

        preprocessor = state["preprocessing_pipeline"]
        prediction_service = ServiceFactory.create_prediction_service(
            model, preprocessor
        )
        explanation_service = ServiceFactory.create_explanation_service(
            prediction_service
        )

        if st.button("Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºÑƒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"):
            with st.spinner("Ğ—Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸..."):
                model_stats = explanation_service.get_model_statistics(model)

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸", model_stats["total_features"])
                    st.metric(
                        "Ğ’ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ²ĞµÑĞ¾Ğ²", f"{model_stats['weight_magnitude']:.4f}"
                    )

                with col2:
                    st.metric("ĞŸĞ¾Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµÑĞ°", model_stats["positive_weights"])
                    st.metric("ĞÑ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ²ĞµÑĞ°", model_stats["negative_weights"])

                with col3:
                    weight_range = f"{model_stats['weight_range']['min']:.3f} to {model_stats['weight_range']['max']:.3f}"
                    st.metric("Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½ Ğ²ĞµÑĞ¾Ğ²", weight_range)
                    st.metric("Ğ¡Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ", f"{model_stats['bias']:.4f}")

                st.subheader("Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑĞ¾Ğ²")
                fig = px.histogram(
                    x=model.weights, nbins=50, title="Distribution of Model Weights"
                )
                st.plotly_chart(fig, width="stretch")


class DataAnalysisPage:
    def render(self, state: AppState) -> None:
        st.title("ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
        st.markdown("---")

        app_config = state.get("app_config", {})

        if state.get("dataset") is None:
            self._render_data_loading(state, app_config)
        else:
            self._render_data_analysis(state)

    def _render_data_loading(self, state: AppState, app_config: dict) -> None:
        st.header("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´ĞµĞ¼Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ")

            data_path = app_config.get("ml_pipeline", {}).get(
                "data_path", "datasets/TitanicDataset.csv"
            )

            st.write(f"Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼: `{data_path}`")

            if st.button("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ¢Ğ¸Ñ‚Ğ°Ğ½Ğ¸ĞºĞ°", type="primary"):
                with st.spinner("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°..."):
                    try:
                        repo = CSVDataRepository(data_path, target_column="Survived")
                        state["dataset"] = repo.load_data()

                        dataset = state["dataset"]
                        if dataset.target is not None:
                            dataset.target = dataset.target.astype(np.float64)

                        st.success("Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° Ğ¸Ğ· {data_path}: {e}")
                        fallback_path = "datasets/TitanicDataset.csv"
                        if data_path != fallback_path:
                            st.info(f"ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ·Ğ°Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚: {fallback_path}")
                            try:
                                repo = CSVDataRepository(
                                    fallback_path, target_column="Survived"
                                )
                                state["dataset"] = repo.load_data()
                                st.success("Ğ—Ğ°Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½!")
                                st.rerun()
                            except Exception as fallback_e:
                                st.error(f"Ğ—Ğ°Ğ¿Ğ°ÑĞ½Ğ¾Ğ¹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ½Ğµ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»: {fallback_e}")

        with col2:
            st.subheader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ")
            uploaded_file = st.file_uploader("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ CSV Ñ„Ğ°Ğ¹Ğ»", type="csv")
            if uploaded_file is not None:
                try:
                    df = pd.read_csv(uploaded_file)
                    st.success(
                        f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(df)} ÑÑ‚Ñ€Ğ¾Ğº Ñ {len(df.columns)} ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ°Ğ¼Ğ¸"
                    )

                    target_col = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ†ĞµĞ»ĞµĞ²ÑƒÑ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ", df.columns)

                    if st.button("ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"):
                        state["dataset"] = Dataset(
                            features=df.drop(columns=[target_col]),
                            target=df[target_col],
                            feature_names=list(df.drop(columns=[target_col]).columns),
                            target_name=target_col,
                        )
                        st.rerun()

                except Exception as e:
                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°: {e}")

    def _create_interactive_plots(self, dataset: Dataset):
        st.subheader("Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸")

        x_axis = st.selectbox("ĞÑÑŒ X", ["Age", "Fare", "Pclass"])
        y_axis = st.selectbox("ĞÑÑŒ Y", ["Fare", "Age", "SibSp"])
        color_by = st.selectbox("Ğ¦Ğ²ĞµÑ‚ Ğ¿Ğ¾", ["Survived", "Pclass", "Sex"])

        fig = px.scatter(
            dataset.features.assign(Survived=dataset.target),
            x=x_axis,
            y=y_axis,
            color=color_by,
            hover_data=["Name"],
            title=f"{y_axis} vs {x_axis} Ğ¿Ğ¾ {color_by}",
        )
        st.plotly_chart(fig)

    def _render_data_analysis(self, state: AppState) -> None:
        dataset = state["dataset"]

        st.header("ĞĞ±Ğ·Ğ¾Ñ€ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°")

        table_component = DataTableComponent()
        table_component.render(dataset.features, "Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ¢Ğ¸Ñ‚Ğ°Ğ½Ğ¸ĞºĞ°")

        st.header("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑĞ²Ğ¾Ğ´ĞºĞ°")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Ğ§Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸")
            st.dataframe(dataset.features.describe(), width="stretch")

        with col2:
            st.subheader("ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸")
            categorical_stats = {}
            for col in dataset.features.select_dtypes(include=["object"]).columns:
                categorical_stats[col] = dataset.features[col].value_counts().head()
            st.json(categorical_stats)

        st.header("Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")

        self._create_interactive_plots(dataset=dataset)

        if st.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°", type="primary"):
            with st.spinner("Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹..."):
                try:
                    visualizer = EDAVisualizer()

                    survival_plots = visualizer.create_survival_analysis_plots(dataset)
                    demographic_plots = visualizer.create_demographic_plots(dataset)
                    correlation_plots = visualizer.create_correlation_analysis(dataset)

                    plot_component = PlotComponent()

                    st.subheader("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ğ¾ÑÑ‚Ğ¸")
                    cols = st.columns(2)
                    for i, (name, path) in enumerate(survival_plots.items()):
                        with cols[i % 2]:
                            plot_component.render(path, name.replace("_", " ").title())

                    st.subheader("Ğ”ĞµĞ¼Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")
                    cols = st.columns(2)
                    for i, (name, path) in enumerate(demographic_plots.items()):
                        with cols[i % 2]:
                            plot_component.render(path, name.replace("_", " ").title())

                    st.subheader("ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·")
                    for name, path in correlation_plots.items():
                        plot_component.render(path, name.replace("_", " ").title())

                except Exception as e:
                    st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ²: {e}")


class ModelTrainingPage:
    def render(self, state: AppState) -> None:
        st.title("ğŸ¤– ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
        st.markdown("---")

        if state.get("dataset") is None:
            st.warning(
                "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ° ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…."
            )
            return

        st.header("ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ")

        training_config = self._render_training_controls()

        if st.button("ĞĞ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", type="primary"):
            self._train_model(state, training_config)

        if state.get("trained_model") is not None:
            self._render_training_results(state)

    def _render_training_controls(self) -> Dict[str, Any]:
        col1, col2, col3 = st.columns(3)

        with col1:
            learning_rate = st.slider("Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", 0.001, 0.5, 0.05, 0.001)
            epochs = st.number_input("Ğ­Ğ¿Ğ¾Ñ…Ğ¸", 1000, 100000, 3000, 100)

        with col2:
            test_size = st.slider("Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‚ĞµÑÑ‚Ğ°", 0.1, 0.5, 0.2, 0.05)
            random_state = st.number_input("Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ", 0, 100, 42)

        with col3:
            convergence_tol = st.number_input(
                "Ğ”Ğ¾Ğ¿ÑƒÑĞº ÑÑ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸",
                1e-8,
                1e-4,
                1e-4,
                1e-8,
            )
            batch_size = st.selectbox("Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ°", ["Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹", 32, 64, 128], index=0)

        return {
            "learning_rate": learning_rate,
            "epochs": epochs,
            "test_size": test_size,
            "random_state": random_state,
            "convergence_tol": convergence_tol,
            "batch_size": batch_size,
        }

    def _train_model(self, state: AppState, config: Dict[str, Any]) -> None:
        try:
            with st.spinner("ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸..."):
                if state.get("preprocessing_pipeline") is None:
                    state["preprocessing_pipeline"] = (
                        PreprocessorFactory.create_titanic_preprocessor()
                    )

                preprocessor = state["preprocessing_pipeline"]
                training_service = ServiceFactory.create_training_service(preprocessor)

                training_config = TrainingConfig(
                    learning_rate=config["learning_rate"],
                    epochs=config["epochs"],
                    test_size=config["test_size"],
                    random_state=config["random_state"],
                    convergence_tol=config["convergence_tol"],
                )

                training_result = training_service.train_model(
                    state["dataset"], training_config
                )
                state["trained_model"] = training_result.model
                state["training_history"] = training_result.learning_curve
                state["training_result"] = training_result

                state["preprocessing_artifacts"] = (
                    training_result.model.preprocessing_artifacts
                )

                if hasattr(training_service, "poly_transformer"):
                    state["trained_model"].preprocessing_artifacts = {
                        "poly_transformer": training_service.poly_transformer,
                        "X_mean": getattr(training_service, "X_mean", None),
                        "X_std": getattr(training_service, "X_std", None),
                    }

                st.success("ĞœĞ¾Ğ´ĞµĞ»ÑŒ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°!")
                st.rerun()

        except Exception as e:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")

    def _render_training_results(self, state: AppState) -> None:
        st.header("Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ")

        model = state["trained_model"]
        training_result = state.get("training_result")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
            st.metric("ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ„Ğ¸Ñ‡", len(model.feature_names))
            st.metric("Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ¾Ñ‚ĞµÑ€Ğ¸", f"{state['training_history'][-1]:.6f}")

            if training_result:
                st.metric("Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", f"{training_result.training_time:.2f}s")
            else:
                st.metric("Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ", "Ğ/Ğ”")

        with col2:
            st.subheader("Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ñ„Ğ¸Ñ‡")
            importance_data = {
                "Ğ¤Ğ¸Ñ‡Ğ°": model.feature_names,
                "Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ": np.abs(model.weights),
            }
            importance_df = pd.DataFrame(importance_data).sort_values(
                "Ğ’Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ", ascending=False
            )
            st.dataframe(importance_df.head(55), width="stretch")

        st.subheader("ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ")

        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=list(range(len(state["training_history"]))),
                y=state["training_history"],
                mode="lines",
                name="ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
                line=dict(color="blue", width=2),
            )
        )

        fig.update_layout(
            title="ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸",
            xaxis_title="Ğ­Ğ¿Ğ¾Ñ…Ğ°",
            yaxis_title="ĞŸĞ¾Ñ‚ĞµÑ€Ğ¸",
            showlegend=True,
            template="plotly_white",
        )

        st.plotly_chart(fig, width="stretch")

        if st.button("ĞÑ†ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ", type="secondary"):
            self._evaluate_model(state)

    def _evaluate_model(self, state: AppState) -> None:
        try:
            with st.spinner("ĞÑ†ĞµĞ½ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸..."):
                preprocessor = state["preprocessing_pipeline"]
                training_service = ServiceFactory.create_training_service(preprocessor)

                evaluation_result = training_service.evaluate_model(
                    state["trained_model"], state["dataset"]
                )

                metrics_component = ModelMetricsComponent()
                metrics_component.render(
                    evaluation_result.classification_report,
                    evaluation_result.confusion_matrix,
                )

        except Exception as e:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ñ†ĞµĞ½ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")


class PredictionPage:
    def render(self, state: AppState) -> None:
        st.title("ğŸ”® ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ")
        st.markdown("---")

        if state.get("trained_model") is None:
            st.warning("ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ° ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.")
            return

        with st.expander("ĞÑ‚Ğ»Ğ°Ğ´Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"):
            model = state["trained_model"]
            st.write(f"ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ„Ğ¸Ñ‡ Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {len(model.feature_names)}")
            st.write(f"ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ñ„Ğ¸Ñ‡: {model.feature_names}")
            st.write(f"Ğ¤Ğ¾Ñ€Ğ¼Ğ° Ğ²ĞµÑĞ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {model.weights.shape}")
            st.write(f"Ğ¡Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {model.bias}")

        st.header("Ğ¡Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ")

        form_component = PredictionFormComponent()
        passenger = form_component.render()

        if passenger is not None:
            self._make_prediction(state, passenger)

        if state.get("current_predictions"):
            self._render_prediction_history(state)

    def _make_prediction(self, state: AppState, passenger: Passenger) -> None:
        try:
            with st.spinner("Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ..."):
                preprocessor = state["preprocessing_pipeline"]
                prediction_service = ServiceFactory.create_prediction_service(
                    state["trained_model"], preprocessor
                )

                prediction_result = prediction_service.predict_survival(passenger)

                if "current_predictions" not in state:
                    state["current_predictions"] = []

                state["current_predictions"].append(prediction_result)

                with st.expander("ĞÑ‚Ğ»Ğ°Ğ´Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ"):
                    st.write(f"Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ: {prediction_result.probability:.4f}")
                    st.write(f"ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ: {prediction_result.prediction}")
                    st.write(f"Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {prediction_result.confidence:.4f}")
                    st.write(f"Ğ¤Ğ¸Ñ‡Ğ¸ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°: {passenger}")

                self._render_prediction_result(prediction_result)

        except Exception as e:
            st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ: {e}")
            st.error(f"Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {str(e)}")

    def _render_prediction_result(self, prediction: Any) -> None:
        st.header("Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ")

        col1, col2 = st.columns(2)

        with col1:
            probability = prediction.probability
            survived = prediction.prediction

            st.metric(
                "Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ",
                f"{probability:.1%}",
                delta="Ğ’Ñ‹Ğ¶Ğ¸Ğ»" if survived else "ĞĞµ Ğ²Ñ‹Ğ¶Ğ¸Ğ»",
                delta_color="normal" if survived else "inverse",
            )

            gauge_fig = go.Figure(
                go.Indicator(
                    mode="gauge+number+delta",
                    value=probability * 100,
                    domain={"x": [0, 1], "y": [0, 1]},
                    title={"text": "Ğ¨Ğ°Ğ½Ñ Ğ²Ñ‹Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ"},
                    delta={"reference": 50},
                    gauge={
                        "axis": {"range": [0, 100]},
                        "bar": {"color": "darkblue"},
                        "steps": [
                            {"range": [0, 30], "color": "lightcoral"},
                            {"range": [30, 70], "color": "lightyellow"},
                            {"range": [70, 100], "color": "lightgreen"},
                        ],
                        "threshold": {
                            "line": {"color": "red", "width": 4},
                            "thickness": 0.75,
                            "value": 50,
                        },
                    },
                )
            )

            st.plotly_chart(gauge_fig, width="stretch")

        with col2:
            st.subheader("Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¿Ğ°ÑÑĞ°Ğ¶Ğ¸Ñ€Ğ°")
            passenger_info = {
                "ĞšĞ»Ğ°ÑÑ": prediction.passenger.pclass,
                "ĞŸĞ¾Ğ»": prediction.passenger.sex,
                "Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚": prediction.passenger.age,
                "Ğ‘Ñ€Ğ°Ñ‚ÑŒÑ/Ğ¡ÑƒĞ¿Ñ€ÑƒĞ³Ğ¸": prediction.passenger.sibsp,
                "Ğ Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸/Ğ”ĞµÑ‚Ğ¸": prediction.passenger.parch,
                "ĞŸĞ»Ğ°Ñ‚Ğ°": f"${prediction.passenger.fare:.2f}",
                "ĞŸĞ¾Ñ€Ñ‚ Ğ¿Ğ¾ÑĞ°Ğ´ĞºĞ¸": prediction.passenger.embarked,
            }

            for key, value in passenger_info.items():
                st.write(f"**{key}:** {value}")

    def _render_prediction_history(self, state: AppState) -> None:
        st.header("Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹")

        history_data = []
        for pred in state["current_predictions"][-10:]:
            history_data.append(
                {
                    "Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ": f"{pred.probability:.1%}",
                    "ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ": "Ğ’Ñ‹Ğ¶Ğ¸Ğ»" if pred.prediction else "ĞĞµ Ğ²Ñ‹Ğ¶Ğ¸Ğ»",
                    "Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚": pred.passenger.age,
                    "ĞšĞ»Ğ°ÑÑ": pred.passenger.pclass,
                    "ĞŸĞ¾Ğ»": pred.passenger.sex,
                    "Ğ’Ñ€ĞµĞ¼Ñ": pred.timestamp.strftime("%H:%M:%S"),
                }
            )

        if history_data:
            st.dataframe(pd.DataFrame(history_data), width="stretch")


class TitanicApp:
    def __init__(self, app_config: dict = None):
        self.pages = {
            "Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ": HomePage(),
            "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…": DataAnalysisPage(),
            "ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸": ModelTrainingPage(),
            "ĞĞ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸": ModelExplanationPage(),
            "ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ": PredictionPage(),
        }
        self.app_config = app_config or {}

    def run(self) -> None:
        st.set_page_config(
            page_title="Titanic Survival Predictor",
            page_icon="ğŸš¢",
            layout="wide",
            initial_sidebar_state="expanded",
        )

        if "app_state" not in st.session_state:
            st.session_state.app_state = {
                "current_page": "Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ",
                "dataset": None,
                "trained_model": None,
                "preprocessing_pipeline": None,
                "current_predictions": [],
                "training_history": [],
                "app_config": self.app_config,
            }

        self._render_sidebar()
        self._render_current_page()

    def _render_sidebar(self) -> None:
        with st.sidebar:
            st.title("ğŸš¢ Titanic ML")
            st.markdown("---")

            selected_page = st.radio(
                "ĞĞ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ",
                list(self.pages.keys()),
                index=list(self.pages.keys()).index(
                    st.session_state.app_state["current_page"]
                ),
            )

            st.session_state.app_state["current_page"] = selected_page

            st.markdown("---")

            st.subheader("Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ")

            app_config = st.session_state.app_state.get("app_config", {})
            data_path = app_config.get("ml_pipeline", {}).get(
                "data_path", "datasets/TitanicDataset.csv"
            )

            dataset_status = (
                "âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½"
                if st.session_state.app_state.get("dataset")
                else "âŒ ĞĞµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½"
            )
            model_status = (
                "âœ… ĞĞ±ÑƒÑ‡ĞµĞ½Ğ°"
                if st.session_state.app_state.get("trained_model")
                else "âŒ ĞĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°"
            )

            st.write(f"Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚: {dataset_status}")
            st.write(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {model_status}")
            st.write(f"ĞŸÑƒÑ‚ÑŒ Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼: {data_path}")

            if st.session_state.app_state.get("dataset"):
                dataset = st.session_state.app_state["dataset"]
                st.write(f"Ğ¡Ñ‚Ñ€Ğ¾ĞºĞ¸: {len(dataset.features)}")
                st.write(f"Ğ¤Ğ¸Ñ‡Ğ¸: {len(dataset.feature_names)}")

            st.markdown("---")

            if st.button("ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", type="secondary"):
                st.session_state.app_state = {
                    "current_page": "Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ",
                    "dataset": None,
                    "trained_model": None,
                    "preprocessing_pipeline": None,
                    "current_predictions": [],
                    "training_history": [],
                    "training_result": None,
                    "app_config": self.app_config,
                }
                st.rerun()

    def _render_current_page(self) -> None:
        current_page = st.session_state.app_state["current_page"]
        page_instance = self.pages[current_page]
        page_instance.render(st.session_state.app_state)
